{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5b432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2677\n",
      "['https://page.kakao.com/content/50866481']\n",
      "현재 작품: 나 혼자만 레벨업\n",
      "       Title                                              Story  \\\n",
      "0  나 혼자만 레벨업  10여 년 전, \\n다른 차원과 이쪽 세계를 이어 주는 통로 ‘게이트’가 열리고 \\...   \n",
      "\n",
      "                                      Hashtags Age Rating  \n",
      "0  #생존, #먼치킨, #시스템, #천재, #노력, #성장, #이능력, #플레이어      전체이용가  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# CSV 파일에서 titleId 값을 가져오기\n",
    "title_df = pd.read_csv(\"kakao_listly.csv\")  # kakao_listly.csv 파일을 불러오기\n",
    "id_list = title_df['url'].astype(str).tolist()  # url 칼럼의 값들을 문자열로 변환하여 리스트로 저장\n",
    "print(len(id_list))\n",
    "print(id_list[:1])\n",
    "\n",
    "# WebDriver 설정\n",
    "options = Options()\n",
    "options.add_argument('headless')  # 헤드리스 모드\n",
    "options.add_argument('window-size=1920x1080')  # 윈도우 크기 설정\n",
    "options.add_argument(\"disable-gpu\")  # GPU 비활성화\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 데이터 저장 리스트\n",
    "data = []\n",
    "\n",
    "# URL 순회하며 정보 수집\n",
    "for url in id_list[:1]:  # 예시로 1개만 크롤링\n",
    "    # 오버뷰 페이지 URL 생성 (제목 추출)\n",
    "    overview_url = f\"{url}?tab_type=overview\"\n",
    "    driver.get(overview_url)\n",
    "    time.sleep(2)  # 페이지가 완전히 로드될 시간을 줍니다.\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # 제목 추출 (오버뷰 페이지에서)\n",
    "    title_span = soup.find(\"span\", class_=\"font-large3-bold mb-3pxr text-ellipsis break-all text-el-70 line-clamp-2\")\n",
    "    title_text = title_span.get_text(strip=True) if title_span else \"제목을 찾을 수 없음\"\n",
    "\n",
    "    # 어바웃 페이지 URL 생성\n",
    "    about_url = f\"{url}?tab_type=about\"\n",
    "    driver.get(about_url)\n",
    "    time.sleep(2)  # 페이지가 완전히 로드될 시간을 줍니다.\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # 줄거리\n",
    "    story_span = soup.find(\"span\", class_=\"font-small1 mb-8pxr block whitespace-pre-wrap break-words text-el-70\")\n",
    "    story_text = story_span.get_text(strip=True) if story_span else \"줄거리를 찾을 수 없음\"\n",
    "\n",
    "    # 해시태그\n",
    "    hashtags = []\n",
    "    hashtag_spans = soup.find_all(\"span\", class_=\"font-small2-bold text-ellipsis text-el-70 line-clamp-1\")\n",
    "    for hashtag in hashtag_spans:\n",
    "        hashtags.append(hashtag.get_text(strip=True))\n",
    "    hashtags_text = ', '.join(hashtags) if hashtags else \"해시태그를 찾을 수 없음\"\n",
    "\n",
    "    # 연령 등급\n",
    "    # 연령 등급은 `span` 태그의 텍스트가 \"전체이용가\" 등으로 정확히 일치하는 텍스트입니다.\n",
    "    age_rating_text = \"연령 등급을 찾을 수 없음\"\n",
    "    info_divs = soup.find_all(\"div\", class_=\"font-small1 flex w-full pt-6pxr\")\n",
    "    for div in info_divs:\n",
    "        label_span = div.find(\"span\")\n",
    "        if label_span and \"연령등급\" in label_span.get_text():\n",
    "            value_span = div.find_all(\"span\")[-1]\n",
    "            age_rating_text = value_span.get_text(strip=True)\n",
    "            break\n",
    "\n",
    "    \n",
    "    # 저장\n",
    "    data.append({\n",
    "        'Title': title_text,\n",
    "        'Story': story_text,\n",
    "        'Hashtags': hashtags_text,\n",
    "        'Age Rating': age_rating_text\n",
    "    })\n",
    "\n",
    "    # 10개 확인용\n",
    "    print(f\"현재 작품: {title_text}\")\n",
    "    time.sleep(3)  # 데이터 확인을 위한 시간\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# DataFrame 생성 및 출력\n",
    "df = pd.DataFrame(data)[['Title', 'Story', 'Hashtags', 'Age Rating']]\n",
    "\n",
    "# CSV로 저장\n",
    "df.to_csv('kakao_crawling_about.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409abba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
