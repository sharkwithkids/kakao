{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b32ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2677\n",
      "['https://page.kakao.com/content/50866481', 'https://page.kakao.com/content/56976992', 'https://page.kakao.com/content/62477346', 'https://page.kakao.com/content/56271898', 'https://page.kakao.com/content/55566760']\n",
      "현재 작품: 나 혼자만 레벨업\n",
      "현재 작품: 접근 불가 레이디\n",
      "현재 작품: 제목 없음\n",
      "현재 작품: 무협지 악녀인데 내가 제일 쎄!\n",
      "현재 작품: 그녀와 야수\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# CSV 파일에서 URL 리스트 가져오기\n",
    "title_df = pd.read_csv(\"kakao_listly.csv\")\n",
    "id_list = title_df['url'].astype(str).tolist()\n",
    "print(len(id_list))\n",
    "print(id_list[:5])  # 잘 불러오는지 확인\n",
    "\n",
    "# WebDriver 설정\n",
    "options = Options()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 데이터 저장 리스트\n",
    "data = []\n",
    "\n",
    "# URL 순회하며 정보 수집\n",
    "for url in id_list[:5]:  # 테스트용으로 5개만 진행\n",
    "    # 오버뷰 페이지 접속\n",
    "    overview_url = f\"{url}?tab_type=overview\"\n",
    "    driver.get(overview_url)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # 제목\n",
    "    title_span = soup.find(\"span\", class_=\"font-large3-bold mb-3pxr text-ellipsis break-all text-el-70 line-clamp-2\")\n",
    "    title_text = title_span.get_text(strip=True) if title_span else \"제목 없음\"\n",
    "\n",
    "    # 작가\n",
    "    writer_span = soup.find(\"span\", class_=\"font-small2 mb-6pxr text-ellipsis text-el-70 opacity-70 break-word-anywhere line-clamp-2\")\n",
    "    writer_text = writer_span.get_text(strip=True) if writer_span else \"작가 없음\"\n",
    "\n",
    "    # 장르 (웹툰 제외)\n",
    "    genre_spans = soup.find_all(\"span\", class_=\"break-all align-middle\")\n",
    "    genres = [g.get_text(strip=True) for g in genre_spans]\n",
    "    genre_text = genres[1] if len(genres) > 1 else \"장르 없음\"\n",
    "\n",
    "    # 조회수 & 별점 (같은 클래스에서 0: 조회수, 1: 별점)\n",
    "    view_rating_spans = soup.find_all(\"span\", class_=\"text-el-70 opacity-70\")\n",
    "    view_count_text = view_rating_spans[0].get_text(strip=True) if len(view_rating_spans) > 0 else \"조회수 없음\"\n",
    "    rating_text = view_rating_spans[1].get_text(strip=True) if len(view_rating_spans) > 1 else \"별점 없음\"\n",
    "\n",
    "    # 회차수 & 댓글수 (같은 클래스에서 0: 회차수, 1: 댓글수)\n",
    "    episode_comment_spans = soup.find_all(\"span\", class_=\"text-ellipsis break-all line-clamp-1 font-small2-bold text-el-70\")\n",
    "    episode_count_text = episode_comment_spans[0].get_text(strip=True) if len(episode_comment_spans) > 0 else \"회차수 없음\"\n",
    "    comment_count_text = episode_comment_spans[1].get_text(strip=True) if len(episode_comment_spans) > 1 else \"댓글수 없음\"\n",
    "\n",
    "    # 어바웃 페이지 접속\n",
    "    about_url = f\"{url}?tab_type=about\"\n",
    "    driver.get(about_url)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # 줄거리\n",
    "    story_span = soup.find(\"span\", class_=\"font-small1 mb-8pxr block whitespace-pre-wrap break-words text-el-70\")\n",
    "    story_text = story_span.get_text(strip=True) if story_span else \"줄거리 없음\"\n",
    "\n",
    "    # 해시태그\n",
    "    hashtags = []\n",
    "    hashtag_spans = soup.find_all(\"span\", class_=\"font-small2-bold text-ellipsis text-el-70 line-clamp-1\")\n",
    "    for tag in hashtag_spans:\n",
    "        hashtags.append(tag.get_text(strip=True))\n",
    "    hashtags_text = ', '.join(hashtags) if hashtags else \"해시태그 없음\"\n",
    "\n",
    "    # 연령 등급\n",
    "    age_rating_text = \"연령 등급 없음\"\n",
    "    info_divs = soup.find_all(\"div\", class_=\"font-small1 flex w-full pt-6pxr\")\n",
    "    for div in info_divs:\n",
    "        label_span = div.find(\"span\")\n",
    "        if label_span and \"연령등급\" in label_span.get_text():\n",
    "            value_span = div.find_all(\"span\")[-1]\n",
    "            age_rating_text = value_span.get_text(strip=True)\n",
    "            break\n",
    "\n",
    "    # 데이터 저장\n",
    "    data.append({\n",
    "        'Title': title_text,\n",
    "        'Writer': writer_text,\n",
    "        'Genre': genre_text,\n",
    "        'View Count': view_count_text,\n",
    "        'Rating': rating_text,\n",
    "        'Episode Count': episode_count_text,\n",
    "        'Comment Count': comment_count_text,\n",
    "        'Story': story_text,\n",
    "        'Hashtags': hashtags_text,\n",
    "        'Age Rating': age_rating_text\n",
    "    })\n",
    "\n",
    "    print(f\"현재 작품: {title_text}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 데이터프레임 생성 및 CSV 저장\n",
    "df = pd.DataFrame(data)[[\n",
    "    'Title', 'Writer', 'Genre', 'View Count', 'Rating',\n",
    "    'Episode Count', 'Comment Count', 'Story', 'Hashtags', 'Age Rating'\n",
    "]]\n",
    "df.to_csv('kakao_crawling_all.csv', index=False, encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
